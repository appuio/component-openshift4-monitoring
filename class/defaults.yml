parameters:
  openshift4_monitoring:
    fallback_team: null

    =_metadata:
      library_aliases:
        prom.libsonnet: openshift4-monitoring-prom.libsonnet
        alert-patching.libsonnet: openshift4-monitoring-alert-patching.libsonnet
      multi_tenant: true
    namespace: openshift-monitoring
    manifests_version: release-4.17
    # no release branches newer than 4.9 exist
    =_operator_lifecycle_manager_map:
      release-4.16: release-4.9
      release-4.17: release-4.9
    jsonnetfile_parameters:
      cmo_version: ${openshift4_monitoring:manifests_version}
      etcd_version: ${openshift4_monitoring:manifests_version}
      # renovate repo=https://github.com/kubernetes/kube-state-metrics
      kube_state_metrics_version: v2.15.0
    defaultConfig:
      nodeSelector:
        node-role.kubernetes.io/infra: ''
    enableUserWorkload: true
    enableAlertmanagerIsolationNetworkPolicy: true
    enableUserWorkloadAlertmanagerIsolationNetworkPolicy: true
    upstreamRules:
      networkPlugin: openshift-sdn
    configs:
      prometheusK8s:
        remoteWrite: []
        _remoteWrite: {}
        externalLabels:
          cluster_id: ${cluster:name}
          cluster_name: ${cluster:display_name}
          tenant_id: ${cluster:tenant}
          tenant_name: ${cluster:tenant_display_name}
        retention: 8d
        volumeClaimTemplate:
          spec:
            resources:
              requests:
                storage: 50Gi
      prometheusOperator: {}
      alertmanagerMain:
        volumeClaimTemplate:
          spec:
            resources:
              requests:
                storage: 2Gi
      kubeStateMetrics: {}
      telemeterClient: {}
      openshiftStateMetrics: {}
      thanosQuerier: {}
      metricsServer: {}
      monitoringPlugin: {}
    configsUserWorkload:
      alertmanager:
        enabled: true
        enableAlertmanagerConfig: true
        volumeClaimTemplate: ${openshift4_monitoring:configs:alertmanagerMain:volumeClaimTemplate}
      prometheusOperator: {}
      prometheus:
        externalLabels:
          cluster_id: ${cluster:name}-user-workload
          cluster_name: "${cluster:display_name} User Workload"
          tenant_id: ${cluster:tenant}
          tenant_name: ${cluster:tenant_display_name}
        retention: 8d
        volumeClaimTemplate: ${openshift4_monitoring:configs:prometheusK8s:volumeClaimTemplate}
      thanosRuler: {}

    remoteWriteDefaults:
      cluster: {}
      userWorkload: {}

    alertManagerConfig:
      route:
        group_wait: 0s
        group_interval: 5s
        repeat_interval: 10m
      inhibit_rules:
        # Don't send warning or info if a critical is already firing
        - target_match_re:
            severity: warning|info
          source_match:
            severity: critical
          equal:
            - namespace
            - alertname
        # Don't send info if a warning is already firing
        - target_match_re:
            severity: info
          source_match:
            severity: warning
          equal:
            - namespace
            - alertname
    alertManagerAutoDiscovery:
      enabled: true
      debug_config_map: false
      team_receiver_format: team_default_%s
      additional_alert_matchers: []
      prepend_routes: []
      append_routes: []
    alerts:
      includeNamespaces:
        - appuio.*
        - cilium
        - default
        - kube-.*
        - openshift-.*
        - syn.*
      excludeNamespaces: []
      ignoreNames:
        - AlertmanagerReceiversNotConfigured
        - CannotRetrieveUpdates
        - ClusterProxyApplySlow
        - ConfigReloaderSidecarErrors
        - FailingOperator
        - GarbageCollectorSyncFailed
        - ImageRegistryStorageReconfigured
        - IngressWithoutClassName
        - KubeCPUOvercommit
        - KubeCPUQuotaOvercommit
        - KubeHpaMaxedOut
        - KubeHpaReplicasMismatch
        - KubeMemoryOvercommit
        - KubeMemoryQuotaOvercommit
        - KubeQuotaExceeded
        - KubeStateMetricsListErrors
        - NodeRAIDDegraded
        - NodeRAIDDiskFailure
        - NodeSystemSaturation
        - NodeTextFileCollectorScrapeError
        - PrometheusOperatorListErrors
        - PrometheusOperatorNodeLookupErrors
        - SchedulerLegacyPolicySet
        - TechPreviewNoUpgrade
        - ThanosQueryGrpcClientErrorRate
        - ThanosQueryGrpcServerErrorRate
        - ThanosQueryHighDNSFailures
        - ThanosRuleAlertmanagerHighDNSFailures
        - ThanosRuleQueryHighDNSFailures
        - node_cpu_load5
      ignoreWarnings:
        - ExtremelyHighIndividualControlPlaneCPU
        - MachineConfigControllerPausedPoolKubeletCA
        - NodeClockNotSynchronising
        - NodeFileDescriptorLimit
        - NodeFilesystemAlmostOutOfFiles
        - NodeFilesystemAlmostOutOfSpace
        - NodeFilesystemFilesFillingUp
        - ThanosRuleRuleEvaluationLatencyHigh
        - etcdDatabaseHighFragmentationRatio
        - etcdExcessiveDatabaseGrowth
        - etcdHighCommitDurations
        - etcdHighFsyncDurations
        - etcdHighNumberOfFailedGRPCRequests
        - etcdMemberCommunicationSlow
      ignoreGroups:
        - CloudCredentialOperator
        - SamplesOperator
        - kube-apiserver-slos-basic
      customAnnotations: {}
      patchRules:
        # rules patched in '*' will be applied regardless of the value of
        # parameter `manifests_version`.
        '*':
          HighOverallControlPlaneMemory:
            annotations:
              description: |
                The overall memory usage is high.
                kube-apiserver and etcd might be slow to respond.
                To fix this, increase memory of the control plane nodes.

                This alert was adjusted to be less sensitive in 4.11.
                Newer Go versions use more memory, if available, to reduce GC pauses.

                Old memory behavior can be restored by setting `GOGC=63`.
                See https://bugzilla.redhat.com/show_bug.cgi?id=2074031 for more details.
            expr: |
              (
                1
                -
                sum (
                  node_memory_MemFree_bytes
                  + node_memory_Buffers_bytes
                  + node_memory_Cached_bytes
                  AND on (instance)
                  label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
                ) / sum (
                  node_memory_MemTotal_bytes
                  AND on (instance)
                  label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
                )
              ) * 100 > 80
          PrometheusRemoteWriteBehind:
            annotations:
              runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/remotewrite.html
          PrometheusRemoteWriteDesiredShards:
            annotations:
              runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/remotewrite.html
          NodeMemoryMajorPagesFaults:
            # Only alert for >100*cores major page faults/node instead of >500/node
            expr: rate(node_vmstat_pgmajfault{job="node-exporter"}[5m]) > on (instance) (count by (instance) (node_cpu_info{}) * 100)
        release-4.16: {}
        release-4.17: {}
      # Alerts to ignore for user workload monitoring
      ignoreUserWorkload: []

    silence:
      schedule: '0 */4 * * *'
      serviceAccountName: prometheus-k8s
      servingCertsCABundleName: serving-certs-ca-bundle
      jobHistoryLimit:
        failed: 3
        successful: 3
      nodeSelector:
        node-role.kubernetes.io/infra: ''
      silences:
        "Silence non syn alerts":
          matchers:
            - name: alertname
              value: ".+"
              isRegex: true
            - name: syn
              value: ""
              isRegex: false

    rules: {}
    images:
      oc:
        image: quay.io/appuio/oc
        tag: v4.18
      node_exporter:
        registry: quay.io
        repository: prometheus/node-exporter
        tag: v1.9.1
      kube_rbac_proxy:
        registry: quay.io
        repository: brancz/kube-rbac-proxy
        tag: v0.19.1

    capacityAlerts:
      enabled: true
      groupByNodeLabels: []
      groups:
        PodCapacity:
          rules:
            TooManyPods:
              enabled: true
              annotations:
                message: 'Only {{ $value }} more pods can be started.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/podcapacity.html#SYN_TooManyPods
                description: 'The cluster is close to the limit of running pods. The cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
            ExpectTooManyPods:
              enabled: false
              annotations:
                message: 'Expected to exceed the threshold of running pods in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/podcapacity.html#SYN_ExpectTooManyPods
                description: 'The cluster is getting close to the limit of running pods. Soon the cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'

        ResourceRequests:
          rules:
            TooMuchMemoryRequested:
              enabled: true
              annotations:
                message: 'Only {{ $value }} memory left for new pods.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/resourcerequests.html#SYN_TooMuchMemoryRequested
                description: 'The cluster is close to assigning all memory to running pods. The cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
            ExpectTooMuchMemoryRequested:
              enabled: false
              annotations:
                message: 'Expected to exceed the threshold of requested memory in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/resourcerequests.html#SYN_ExpectTooMuchMemoryRequested
                description: 'The cluster is getting close to assigning all memory to running pods. Soon the cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'
            TooMuchCPURequested:
              enabled: true
              annotations:
                message: 'Only {{ $value }} cpu cores left for new pods.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/resourcerequests.html#SYN_TooMuchCPURequested
                description: 'The cluster is close to assigning all CPU resources to running pods. The cluster might not be able to handle node failures and might soon not be able to start new pods. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
            ExpectTooMuchCPURequested:
              enabled: false
              annotations:
                message: 'Expected to exceed the threshold of requested CPU resources in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/resourcerequests.html#SYN_ExpectTooMuchCPURequested
                description: 'The cluster is getting close to assigning all CPU cores to running pods. Soon the cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'

        MemoryCapacity:
          rules:
            ClusterLowOnMemory:
              enabled: true
              annotations:
                message: 'Only {{ $value }} free memory on Worker Nodes.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/memorycapacity.html#SYN_ClusterMemoryUsageHigh
                description: 'The cluster is close to using all of its memory. The cluster might not be able to handle node failures or load spikes. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
            ExpectClusterLowOnMemory:
              enabled: false
              annotations:
                message: 'Cluster expected to run low on memory in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/memorycapacity.html#SYN_ExpectClusterMemoryUsageHigh
                description: 'The cluster is getting close to using all of its memory. Soon the cluster might not be able to handle node failures or load spikes. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'

        CpuCapacity:
          rules:
            ClusterCpuUsageHigh:
              enabled: true
              annotations:
                message: 'Only {{ $value }} idle cpu cores accross cluster.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/cpucapacity.html#SYN_ClusterCpuUsageHigh
                description: 'The cluster is close to using up all CPU resources. The cluster might not be able to handle node failures or load spikes. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1

            ExpectClusterCpuUsageHigh:
              enabled: false
              annotations:
                message: 'Cluster expected to run low on available CPU resources in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/cpucapacity.html#SYN_ExpectClusterCpuUsageHigh
                description: 'The cluster is getting close to using up all CPU resources. The cluster might soon not be able to handle node failures or load spikes. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'

        UnusedCapacity:
          rules:
            ClusterHasUnusedNodes:
              enabled: true
              annotations:
                message: 'Cluster has unused nodes.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/unusedcapacity.html#SYN_ClusterHasUnusedNodes
                description: 'The cluster has {{ $value }} unused nodes. Consider removing unused nodes.'
              for: 8h
              labels: {}
              expr:
                # How many nodes need to be unused.
                # There should be some overcapacity to account for failing nodes and future growth.
                reserved: 4

    secrets: {}

    cronjobs: {}

    customNodeExporter:
      enabled: false
      collectors:
        - network_route
      args: []
      metricRelabelings:
        # only keep routes for host interfaces (assumes that host interfaces
        # are `ensX` which should hold on RHCOS)
        - action: keep
          sourceLabels: ['__name__', 'device']
          regex: 'node_network_route.*;ens.*'
