= Parameters

The parent key for all of the following parameters is `openshift4_monitoring`.

== `manifests_version`

[horizontal]
type:: string
default:: `release-4.17`

Select which version of the upstream alerting (and recording) rules should be used by the component.
This parameter must be changed to match the cluster's OCP4 minor version.

[TIP]
====
We recommend setting this parameter based on the reported OpenShift version which can be found in the cluster's https://syn.tools/syn/SDDs/0027-dynamic-cluster-facts.html[dynamic facts].

[source,yaml]
----
manifests_version: release-${dynamic_facts:openshiftVersion:Major}.${dynamic_facts:openshiftVersion:Minor}
----
====

== `defaultConfig`

[horizontal]
type:: dictionary
default::
+
[source,yaml]
----
nodeSelector:
  node-role.kubernetes.io/infra: ''
----

A dictionary holding the default configuration which should be applied to all components.

NOTE: The contents of this parameter aren't applied to components `nodeExporter` and `prometheusOperatorAdmissionWebhook` which don't support field `nodeSelector`.


== `enableAlertmanagerIsolationNetworkPolicy`

[horizontal]
type:: boolean
default:: `true`

Blocks all traffic to Alertmanager pods except the allowed API traffic.

This works around an observed accidental clustering with user workload or custom Alertmanager clusters in other namespaces.


== `enableUserWorkloadAlertmanagerIsolationNetworkPolicy`

[horizontal]
type:: boolean
default:: `true`

Blocks all traffic to Alertmanager pods except the allowed API traffic.

This works around an observed accidental clustering with system or custom Alertmanager clusters in other namespaces.


== `enableUserWorkload`

[horizontal]
type:: boolean
default:: `true`

A parameter to enable https://docs.openshift.com/container-platform/latest/monitoring/enabling-monitoring-for-user-defined-projects.html[monitoring for user-defined projects].

== `configs`

[horizontal]
type:: dictionary
default:: https://github.com/appuio/component-openshift4-monitoring/blob/master/class/defaults.yml[See `class/defaults.yml`]

A dictionary holding the configurations for the https://docs.openshift.com/container-platform/latest/monitoring/configuring-the-monitoring-stack.html#configuring-the-monitoring-stack_configuring-the-monitoring-stack[monitoring components].

The component will remove empty fields (`null`, and empty lists or objects) from the provided configuration.

See the https://docs.openshift.com/container-platform/latest/monitoring/cluster_monitoring/configuring-the-monitoring-stack.html[OpenShift docs] for available parameters.

This table shows the monitoring components you can configure and the keys used to specify the components:

[options="header"]
|====
|Component|Key
|Prometheus Operator|`prometheusOperator`
|Prometheus Operator admission webhook|`prometheusOperatorAdmissionWebhook`
|Prometheus|`prometheusK8s`
|Alertmanager|`alertmanagerMain`
|kube-state-metrics|`kubeStateMetrics`
|openshift-state-metrics|`openshiftStateMetrics`
|Telemeter Client|`telemeterClient`
|Metrics Server|`metricsServer`
|Thanos Querier|`thanosQuerier`
|Node exporter|`nodeExporter`
|Console monitoring plugin|`monitoringPlugin`
|====

=== `configs.prometheusK8s._remoteWrite`

[horizontal]
type:: dictionary
default:: `{}`
example::
+
[source,yaml]
----
_remoteWrite:
  example:
    url: https://prometheus.example.com/api/v1/write
    headers:
      "X-Scope-OrgID": example
    writeRelabelConfigs:
      - action: keep
        sourceLabels: ['syn']
        regex: '.+'
      - action: keep
        timeseries:
          - foo_metric_one
          - foo_metric_two
    basicAuth:
      username:
        name: remote-write
        key: username
      password:
        name: remote-write
        key: password
----

A dictionary holding the remote write configurations for the Prometheus component.
The key is the name of the configuration, the value is the content of the configuration.

The remote write configuration will be appended to the `configs.prometheusK8s.remoteWrite` parameter for backwards compatibility.

In this configuration only, `writeRelabelConfigs` entries can hold an entry for `timeseries` containing a list of strings representing individual Prometheus timeseries.
These will be translated into a `regex` entry, with a regular expression matching any one of the listed timeseries.

== `configsUserWorkload`

[horizontal]
type:: dictionary
default::
+
[source,yaml]
----
alertmanager:
  enabled: true
  enableAlertmanagerConfig: true
  volumeClaimTemplate: ${openshift4_monitoring:configs:alertmanagerMain:volumeClaimTemplate}
prometheusOperator: {}
prometheus:
  retention: 8d
  volumeClaimTemplate: ${openshift4_monitoring:configs:prometheusK8s:volumeClaimTemplate}
thanosRuler: {}
----

A dictionary holding the configurations for the https://docs.openshift.com/container-platform/latest/monitoring/configuring-the-monitoring-stack.html#configuring-the-monitoring-stack_configuring-the-monitoring-stack[user workload monitoring components].

By default, we configure the user workload monitoring Prometheus and Alertmanager to inherit the `volumeClaimTemplate` specifications from the cluster-monitoring config.
This allows users to configure the default storageclass and volume size of both monitoring stacks through the cluster-monitoring config.

This table shows the monitoring components you can configure and the keys used to specify the components:

[options="header"]
|====
|Component|Key|Note
|Alertmanager|`alertmanager`|Only on OpenShift 4.11 and newer
|Prometheus Operator|`prometheusOperator`|
|Prometheus|`prometheus`|
|Thanos Ruler|`thanosRuler`|
|====

=== `configsUserWorkload.prometheus._remoteWrite`

[horizontal]
type:: dictionary
default:: `{}`
example::
+
[source,yaml]
----
_remoteWrite:
  example:
    url: https://prometheus.example.com/api/v1/write
    headers:
      "X-Scope-OrgID": customer
    writeRelabelConfigs:
      - sourceLabels: ['customer']
        regex: '.+'
        action: keep
    basicAuth:
      username:
        name: remote-write-customer
        key: username
      password:
        name: remote-write-customer
        key: password
----

A dictionary holding the remote write configurations for the Prometheus component of the user workload monitoring stack.
The key is the name of the configuration, the value is the content of the configuration.

The remote write configuration will be appended to the `configsUserWorkload.prometheus.remoteWrite` parameter for backwards compatibility.


== `alertManagerConfig`

[horizontal]
type:: dictionary
default::
+
[source,yaml]
----
route:
  group_wait: 0s
  group_interval: 5s
  repeat_interval: 10m
inhibit_rules:
  # Don't send warning or info if a critical is already firing
  - target_match_re:
      severity: warning|info
    source_match:
      severity: critical
    equal:
      - namespace
      - alertname
  # Don't send info if a warning is already firing
  - target_match_re:
      severity: info
    source_match:
      severity: warning
    equal:
      - namespace
      - alertname
----

A dictionary holding the configuration for the AlertManager.

See the https://docs.openshift.com/container-platform/latest/monitoring/managing-alerts.html#applying-custom-alertmanager-configuration_managing-alerts[OpenShift docs] for available parameters.

The component will silently drop any fields in the provided config which are empty.
The component treats `null` as empty for scalar fields.

== `alertManagerAutoDiscovery`

[horizontal]
type:: dictionary
default::
+
[source,yaml]
----
alertManagerAutoDiscovery:
  enabled: true
  debug_config_map: false
  team_receiver_format: team_default_%s
  additional_alert_matchers: []
  prepend_routes: []
  append_routes: []
----

`alertManagerAutoDiscovery` holds the configuration for the Alertmanager auto-discovery feature.

The auto-discovery routes alerts to the configured teams based on their namespaces and the top-level `syn.teams[*].instances` and `syn.owner` parameters.
Auto-discovery first creates a list of Commodore component instances by parsing the `applications` array using the same rules as Commodore itself (see also the https://syn.tools/commodore/reference/architecture.html#_component_instantiation[Commodore component instantiation documentation]).
For each discovered instance, the component then reads the component's namespace from field `namespace` or `namespace.name` in the rendered parameters of this component.
Finally, routing rules are generated to route alerts from the discovered namespaces to the associated component instance's owning team.

[NOTE]
====
Without special handling, the namespace discovery would discover namespace `openshift4-monitoring` for component instances that use `namespace: ${_instance}`.
This is the case because we read the instance's namespace from the rendered parameters for component openshift4-monitoring and therefore `${_instance}` resolves to `openshift4-monitoring`.

To address this case, the component has override logic in the namespace discovery for component instances which use `${_instance}` in their namespace definition.
The override logic replaces all occurrences of `openshift4-monitoring` in the discovered namespace with the instance name for instances other than `openshift4-monitoring`.
====

.`syn` Team Example
[source,yaml]
----
syn:
  owner: daring-donkeys
  teams:
    electric-elephants:
      instances: [postgres]
----

The auto-discovery feature is enabled by default.
A ConfigMap can be enabled with `debug_config_map` to debug the auto-discovery feature.

The configuration is merged with the `alertManagerConfig` parameter.
Route receivers are generated for each team based on the `team_receiver_format` parameter.
The routes are ordered as follows:

[source]
----
alertManagerAutoDiscovery.prepend_routes + generated routes + alertManagerAutoDiscovery.append_routes + alertManagerConfig.routes + route all to syn.owner
----

`additional_alert_matchers` is a list of additional alert matchers to add to the generated routes.
This can be used to handle special cases where the auto-discovery feature does not work as expected.
For example if an alert should go to a different team than the namespace suggests based on a label.

[source,yaml]
----
alertManagerAutoDiscovery:
  additional_alert_matchers:
    - 'syn_team = ""'
# becomes
- continue: true
  matchers:
    - syn_team = ""
    - namespace =~ "my-ns"
  receiver: team_default_lovable-lizards
- continue: false
  matchers:
    - syn_team = ""
    - namespace =~ "my-ns"
  receiver: __component_openshift4_monitoring_null
----

== `operatorRuleNamespaces`

[horizontal]
type:: list
default:: `[]`

Additional namespaces to manage operator managed PrometheusRules.

== `alerts`

[horizontal]
type:: dictionary

Configuration parameters related to influence the resulting alert rules.

=== `includeNamespaces`

[horizontal]
type:: list
default:: https://github.com/appuio/component-openshift4-monitoring/blob/master/class/defaults.yml[See `class/defaults.yml`]

List of namespace patterns to use for alerts which have `namespace=~"(openshift-.\*|kube-.*|default)"` in the upstream rule.
The component generates a regex pattern from the list by concatenating all elements into a large OR-regex.
To inject the custom regex, the component searches for the exact string `namespace=~"(openshift-.\*|kube-.*|default)"` in field `expr` of each alert rule and replaces it with the regex generated from this parameter and parameter `excludeNamespaces`.

The component processes the list with `com.renderArray()` to allow users to drop entries in the hierarchy.

IMPORTANT: The component doesn't validate that the list entries are valid regex patterns.

==== Example

We assume that the input config has patterns `default` and `syn.*`:

[source,yaml]
----
includeNamespaces:
  - default
  - syn.*
----

The component will generate namespace selector `namespace=~"(default|syn.*)"` from this input configuration.

=== `excludeNamespaces`

[horizontal]
type:: list
default:: `[]`

List of namespace patterns to exclude for alerts which have `namespace=~"(openshift-.\*|kube-.*|default)"` in the upstream rule.
The component generates a regex pattern from the list by concatenating all elements into a large OR-regex.
To inject the custom regex, the component searches for the exact string `namespace=~"(openshift-.\*|kube-.*|default)"` in field `expr` of each alert rule and replaces it with the regex generated from this parameter and parameter `includeNamespaces`.

The component processes the list with `com.renderArray()` to allow users to drop entries in the hierarchy.

IMPORTANT: The component doesn't validate that the list entries are valid regex patterns.

==== Example

We assume that the input config has patterns `default` and `openshift.*` and `syn.*` for `includeNamespaces` and `openshift-adp` for `excludeNamespaces`:

[source,yaml]
----
includeNamespaces:
  - default
  - openshift.*
  - syn.*
excludeNamespaces:
  - openshift-adp
----

The component will generate namespace selector `namespace=~"(default|openshift.*|syn.*)",namespace!~"(openshift-adp)"` from this input configuration.

=== `ignoreNames`

[horizontal]
type:: list
default:: https://github.com/appuio/component-openshift4-monitoring/blob/master/class/defaults.yml[See `class/defaults.yml`]

List of alert rule names to be dropped.

NOTE: This parameter is taken into account in the `filterRules` and `filterPatchRules` library functions.

=== `ignoreWarnings`

[horizontal]
type:: list
default:: https://github.com/appuio/component-openshift4-monitoring/blob/master/class/defaults.yml[See `class/defaults.yml`]

List of alert rule names for which to drop alerts with label `severity: warning`.

NOTE: In contrast to `ignoreNames`, this parameter is not taken into account in the `filterRules` and `filterPatchRules` library functions.

=== `ignoreGroups`

[horizontal]
type:: list
default:: https://github.com/appuio/component-openshift4-monitoring/blob/master/class/defaults.yml[See `class/defaults.yml`]

List of complete alert rule groups to drop.

NOTE: This parameter is not taken into account for `filterRules` and `filterPatchRules`.

=== `customAnnotations`

[horizontal]
type:: dict
default:: `{}`

Maps alert names to sets of custom annotations.
Allows configuring custom annotations for individual alerts.

Example:

[source,yaml]
----
customAnnotations:
  Watchdog:
    runbook_url: https://www.google.com/?q=Watchdog
----

=== `patchRules`
type:: dict
default:: See https://github.com/appuio/component-openshift4-monitoring/blob/master/class/defaults.yml[`class/defaults.yml` on GitHub]

The parameter `patchRules` allows users to customize upstream alerts.
The component expects that top-level keys in the parameter correspond to the name of the alert.

The component expects alert names as keys and any alert configuration as values in each top-level key.
See the Prometheus https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/[alerting rules documentation] for extended documentation on configuring alerting rules.

Example:

[source,yaml]
----
patchRules:
  PrometheusRemoteWriteBehind:
    annotations:
      runbook_url: https://example.com/runbooks/PrometheusRemoteWriteBehind.html
  SystemMemoryExceedsReservation:
    for: 30m
----

=== `ignoreUserWorkload`

[horizontal]
type:: list
default:: `[]`

A list of alerting rules for which the component should patch the `expr` and `annotations.description` fields to ensure they don't alert for the user workload monitoring stack.

By default, we don't turn off any alerts for the user workload monitoring stack.

The parameter supports removing entries by providing the entry to remove prefixed with `~`.
The parameter can be completely cleared with the following config:

[source,yaml]
----
parameters:
  openshift4_monitoring:
    alerts:
      ~ignoreUserWorkload: []
----


== `silence`

[horizontal]
type:: dict

Parameters to configure the silence CronJob.


== `silence.silences`

[horizontal]
type:: dict
default::
+
[source,yaml]
----
"Silence non syn alerts":
  matchers:
    - name: alertname
      value: ".+"
      isRegex: true
    - name: syn
      value: ""
      isRegex: false
----

Contains the list of silences to be applied.
The key is used as the comment of the silence and the value is a dictionary which is passed to Alertmanager.

Silences removed from the hierarchy stay active in Alertmanager for up to 24h until they expire.

Silences all non-SYN alerts by default.

=== `schedule`

[horizontal]
type:: string
default:: '0 */4 * * *'

Schedule of the CronJob in cron syntax.

=== `serviceAccountName`

[horizontal]
type:: string
default:: prometheus-k8s

Name of the service account used when running the silence job.
The service account must have permission to access the Alertmanager service through its oAuth proxy.

=== `servingCertsCABundleName`

[horizontal]
type:: string
default:: serving-certs-ca-bundle

Name of the config map containing the CA bundle of the Alertmanager service.

=== `jobHistoryLimit`

[horizontal]
type:: dict

Parameters to configure the numbers of silence job objects to keep.

==== `failed`

[horizontal]
type:: number
default:: 3

Number of failed jobs to keep.

==== `successful`

[horizontal]
type:: number
default:: 3

Number of successful jobs to keep.

== `capacityAlerts`

[horizontal]
type:: dict

This parameter allows users to enable and configure alerts for capacity management.
The capacity alerts are enabled by default and can be disabled completely by setting the key `capacityAlerts.enabled` to `false`.
Predictive alerts are disabled by default and can be enabled individually as shown below by setting `ExpectClusterCpuUsageHigh.enabled` to `true`.

The dictionary will be transformed into a `PrometheusRule` object by the component.

The component provides 10 alerts that are grouped in four groups.
You can disable or modify each of these alert rules individually.
The fields in these rules will be added to the final `PrometheusRule`, with the exception of `expr`.
The `expr` field contains fields which can be used to tune the default alert rule.
Alternatively the default rule can be completely overwritten by setting the `expr.raw` field (see example below).
See xref:explanations/resource_management.adoc[Resource Management] for an explanation for every alert rule.

Example:

[source,yaml]
----
capacityAlerts:
  enabled: true <1>
  groupByNodeLabels: [] <2>
  groups:
    PodCapacity:
      rules:
        TooManyPods:
          annotations:
            message: 'The number of pods is too damn high' <3>
          for: 3h <4>
        ExpectTooManyPods:
          expr: <5>
            range: '2d'
            predict: '5*24*60*60'

    ResourceRequests:
      rules:
        TooMuchMemoryRequested:
          enabled: true
          expr:
            raw: sum(kube_pod_resource_request{resource="memory"}) > 9000*1024*1024*1024 <6>
    CpuCapacity:
      rules:
        ClusterCpuUsageHigh:
          enabled: false <7>
        ExpectClusterCpuUsageHigh:
          enabled: false <7>
    UnusedCapacity:
      rules:
        ClusterHasUnusedNodes:
          enabled: false <8>
----
<1> Enables capacity alerts
<2> List of node labels (as they show up in the `kube_node_labels` metric) by which alerts are grouped
<3> Changes the alert message for the pod capacity alert
<4> Only alerts for pod capacity if it fires for 3 hours
<5> Change the pod count prediction to look at the last two days and predict the value in five days
<6> Completely overrides the default alert rule and alerts if the total memory request is over 9000 GB
<7> Disables both CPU capacity alert rules
<8> Disables alert if the cluster has unused nodes.


== `rules`

[horizontal]
type:: dict
default:: `{}`

This parameter allows users to configure additional Prometheus rules to deploy on the cluster.

Each key-value pair in the dictionary is transformed into a `PrometheusRule` object by the component.

The component expects that values are dicts themselves and expects that keys in those dicts are prefixed with `record:` or `alert:` to indicate whether the rule is a recording or alerting rule.
The component will transform the keys into fields in the resulting rule by taking the prefix as the field name and the rest of the key as the field value.
For example, key `"record:sum:some:metric:5m"` would be transformed into `record: sum:some:metric:5m` which should define a recording rule with name `sum:some:metric:5m`.
This field is then merged into the provided value which should be a valid rule definition.

See the Prometheus docs for supported configurations for https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/[recording] and https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/[alerting] rules.


Example:

[source,yaml]
----
rules:
  generic-rules:
    "alert:ContainerOOMKilled":
      annotations:
        message: A container ({{$labels.container}}) in pod {{ $labels.namespace }}/{{ $labels.pod }} was OOM killed
      expr: |
        kube_pod_container_status_last_terminated_reason{reason="OOMKilled"} == 1
      labels:
        source: https://git.vshn.net/swisscompks/syn-tenant-repo/-/blob/master/common.yml
        severity: devnull
----

== Example

[source,yaml]
----
defaultConfig:
  nodeSelector:
    node-role.kubernetes.io/infra: ''
configs:
  prometheusK8s:
    volumeClaimTemplate:
      spec:
        resources:
          requests:
            storage: 100Gi
alerts:
  ignoreNames:
    - KubeAPIErrorsHigh
    - KubeClientErrors
----

== `secrets`

[horizontal]
type:: dict
default:: `{}`

A dict of secrets to create in the namespace.
The key is the name of the secret, the value is the content of the secret.
The value must be a dict with a key `stringData` which is a dict of key/value pairs to add to the secret.

== `remoteWriteDefaults`

[horizontal]
type:: dict
default::
+
[source,yaml]
----
remoteWriteDefaults:
  cluster: {}
  userWorkload: {}
----
example::
+
[source,yaml]
----
remoteWriteDefaults:
  cluster:
    queueConfig:
      maxShards: 80
  userWorkload:
    queueConfig:
      maxShards: 20
----

A dict of default remote write configurations for the Prometheus component.
Those values are merged into each remote write configuration in `configs.prometheusK8s.remoteWrite` and `configsUserWorkload.prometheus.remoteWrite`.


== `cronjobs`

[horizontal]
type:: dict

A dict of arbitrary cronjobs to create in the `openshift-monitoring` namespace.
The key is the name of the cronjob and the values are its configuration options as shown below.

=== `schedule`

[horizontal]
type:: string

Schedule of the CronJob in cron syntax.

=== `script`

[horizontal]
type:: string

The script to execute as part of the cronjob.

=== `image`

[horizontal]
type:: dict
default:: `images.oc` from https://github.com/appuio/component-openshift4-monitoring/blob/master/class/defaults.yml[`class/defaults.yml`]

=== `image.image`

[horizontal]
type:: string

The image used by the cronjob.

=== `image.tag`

[horizontal]
type:: string

The image tag used by the cronjob.

=== `config`

[horizontal]
type:: dict
default:: `{}`

Any additional custom configuration for the cronjob.

=== Example

[source,yaml]
----
cronjobs:
  my-cronjob:
    schedule: "1 * * * *"
    image:
      image: quay.io/appuio/oc
      tag: v4.13
    script: |
      #!/bin/sh
      echo "this is an example"
    config:
      spec:
        failedJobsHistoryLimit: 1
----

== `customNodeExporter`

This parameter allows users to deploy an additional node-exporter DaemonSet.
We provide this option, since OpenShift's cluster-monitoring stack currently doesn't allow users to customize the bundled node-exporter DaemonSet.

Currently, the parameter is tailored to allow users to run an additional node-exporter which enables collectors that aren't enabled in the default node exporter.

The configuration is rendered by using the same Jsonnet that's used by the OpenShift cluster-monitoring stack to generate the default node-exporter DaemonSet.
The component further customizes the resulting manifests to ensure that there's no conflicts between the default node-exporter and the additional node-exporter.

The additional node-exporter is deployed in the namespace indicated by parameter `namespace`.
By default this is namespace `openshift-monitoring`.
The component also deploys a `ServiceMonitor` which ensures that the additional node-exporter is scraped by the cluster-monitoring stack's Prometheus.

Users can configure arbitrary recording and alerting rules which use metrics scraped from the additional node-exporter via parameter `rules`.

=== `enabled`

[horizontal]
type:: bool
default:: `false`

Whether to deploy the additional node-exporter.

=== `collectors`

[horizontal]
type:: list
default:: `["network_route"]`

Which collectors to enable in the additional node-exporter.
By default, all collectors are disabled.
Users can remove entries from this list by providing an existing entry prefixed with `~`.

=== `args`
[horizontal]
type:: list
default:: `[]`


Additional command line arguments to pass to the additional node-exporter.
Please note that specifying `--[no-]collector.<name>` here will break the DaemonSet, since `node-exporter` doesn't support specifying these flags multiple times.
Users should use parameter `customNodeExporter.collectors` to enable collectors.

=== `metricRelabelings`

[horizontal]
type:: list
default:: https://github.com/appuio/component-openshift4-monitoring/blob/master/class/defaults.yml[See `class/defaults.yml`]

This parameter allows users to specify the content of field `metricRelabelings` of the `ServiceMonitor` which is created for the additional node-exporter.
By default, the component drops all metrics except `node_network_route*` metrics for host devices prefixed with `ens`.
Since this component only applies to OpenShift 4, we know that any node's host interfaces will use device names that are prefixed with `ens`.

Users are encouraged to extend or overwrite this parameter to ensure all the metrics they're interested in are actually scraped by Prometheus.
