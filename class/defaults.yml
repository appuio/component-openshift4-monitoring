parameters:
  openshift4_monitoring:
    =_metadata:
      library_aliases:
        prom.libsonnet: openshift4-monitoring-prom.libsonnet
        alert-patching.libsonnet: openshift4-monitoring-alert-patching.libsonnet
    namespace: openshift-monitoring
    # TODO: select based on reported OCP version once we have dynamic facts
    manifests_version: release-4.9
    =_cluster_monitoring_operator_version_map:
      release-4.9: release-4.9
      release-4.10: release-4.10
      release-4.11: release-4.11
    =_etcd_operator_version_map:
      release-4.9: release-4.9
      release-4.10: release-4.10
      release-4.11: release-4.11
    =_operator_lifecycle_manager_map:
      release-4.9: release-4.9
      release-4.10: release-4.9 # no 4.10 release yet
      release-4.11: release-4.9 # no 4.11 release yet
    jsonnetfile_parameters:
      cmo_version: ${openshift4_monitoring:_cluster_monitoring_operator_version_map:${openshift4_monitoring:manifests_version}}
      etcd_version: ${openshift4_monitoring:_etcd_operator_version_map:${openshift4_monitoring:manifests_version}}
    defaultConfig:
      nodeSelector:
        node-role.kubernetes.io/infra: ''
    enableUserWorkload: true
    upstreamRules:
      networkPlugin: openshift-sdn
      elasticsearchOperator: true
      clusterSamplesOperator: true
    configs:
      prometheusK8s:
        remoteWrite: []
        _remoteWrite: {}
        externalLabels:
          cluster_id: ${cluster:name}
          tenant_id: ${cluster:tenant}
        retention: 8d
        volumeClaimTemplate:
          spec:
            resources:
              requests:
                storage: 50Gi
      prometheusOperator: {}
      alertmanagerMain:
        volumeClaimTemplate:
          spec:
            resources:
              requests:
                storage: 2Gi
      kubeStateMetrics: {}
      grafana: {}
      telemeterClient: {}
      k8sPrometheusAdapter: {}
      openshiftStateMetrics: {}
      thanosQuerier: {}
    configsUserWorkload:
      alertmanager:
        enabled: true
        enableAlertmanagerConfig: true
        volumeClaimTemplate: ${openshift4_monitoring:configs:alertmanagerMain:volumeClaimTemplate}
      prometheusOperator: {}
      prometheus:
        retention: 8d
        volumeClaimTemplate: ${openshift4_monitoring:configs:prometheusK8s:volumeClaimTemplate}
      thanosRuler: {}
    alertManagerConfig:
      route:
        group_wait: 0s
        group_interval: 5s
        repeat_interval: 10m
      inhibit_rules:
        # Don't send warning or info if a critical is already firing
        - target_match_re:
            severity: warning|info
          source_match:
            severity: critical
          equal:
            - namespace
            - alertname
        # Don't send info if a warning is already firing
        - target_match_re:
            severity: info
          source_match:
            severity: warning
          equal:
            - namespace
            - alertname
    alerts:
      includeNamespaces:
        - appuio.*
        - cilium
        - default
        - kube-.*
        - openshift-.*
        - syn.*
      ignoreNames:
        - AlertmanagerReceiversNotConfigured
        - CannotRetrieveUpdates
        - ClusterProxyApplySlow
        - ConfigReloaderSidecarErrors
        - FailingOperator
        - GarbageCollectorSyncFailed
        - ImageRegistryStorageReconfigured
        - KubeCPUOvercommit
        - KubeCPUQuotaOvercommit
        - KubeHpaMaxedOut
        - KubeHpaReplicasMismatch
        - KubeMemoryOvercommit
        - KubeMemoryQuotaOvercommit
        - KubeQuotaExceeded
        - KubeStateMetricsListErrors
        - NodeRAIDDegraded
        - NodeRAIDDiskFailure
        - NodeTextFileCollectorScrapeError
        - PrometheusOperatorListErrors
        - PrometheusOperatorNodeLookupErrors
        - SchedulerLegacyPolicySet
        - TechPreviewNoUpgrade
        - ThanosQueryGrpcClientErrorRate
        - ThanosQueryGrpcServerErrorRate
        - ThanosQueryHighDNSFailures
        - ThanosRuleAlertmanagerHighDNSFailures
        - ThanosRuleQueryHighDNSFailures
        - node_cpu_load5
      ignoreWarnings:
        - ExtremelyHighIndividualControlPlaneCPU
        - MachineConfigControllerPausedPoolKubeletCA
        - NodeClockNotSynchronising
        - NodeFileDescriptorLimit
        - NodeFilesystemAlmostOutOfFiles
        - NodeFilesystemAlmostOutOfSpace
        - NodeFilesystemFilesFillingUp
        - PodDisruptionBudgetAtLimit
        - ThanosRuleRuleEvaluationLatencyHigh
        - etcdDatabaseHighFragmentationRatio
        - etcdExcessiveDatabaseGrowth
        - etcdHighCommitDurations
        - etcdHighFsyncDurations
        - etcdHighNumberOfFailedGRPCRequests
        - etcdMemberCommunicationSlow
      ignoreGroups:
        - CloudCredentialOperator
        - SamplesOperator
        - kube-apiserver-slos-basic
      customAnnotations: {}
      patchRules:
        release-4.11:
          HighOverallControlPlaneMemory:
            annotations:
              description: |
                The overall memory usage is high.
                kube-apiserver and etcd might be slow to respond.
                To fix this, increase memory of the control plane nodes.

                This alert was adjusted to be less sensitive in 4.11.
                Newer Go versions use more memory, if available, to reduce GC pauses.

                Old memory behavior can be restored by setting `GOGC=63`.
                See https://bugzilla.redhat.com/show_bug.cgi?id=2074031 for more details.
            expr: |
              (
                1
                -
                sum (
                  node_memory_MemFree_bytes
                  + node_memory_Buffers_bytes
                  + node_memory_Cached_bytes
                  AND on (instance)
                  label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
                ) / sum (
                  node_memory_MemTotal_bytes
                  AND on (instance)
                  label_replace( kube_node_role{role="master"}, "instance", "$1", "node", "(.+)" )
                )
              ) * 100 > 80
          PrometheusRemoteWriteBehind:
            annotations:
              runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/remotewrite.html
          PrometheusRemoteWriteDesiredShards:
            annotations:
              runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/remotewrite.html
      # Alerts to ignore for user workload monitoring
      ignoreUserWorkload: []

    silence:
      schedule: '0 */4 * * *'
      serviceAccountName: prometheus-k8s
      servingCertsCABundleName: serving-certs-ca-bundle
      jobHistoryLimit:
        failed: 3
        successful: 3
      nodeSelector:
        node-role.kubernetes.io/infra: ''
      silences:
        "Silence non syn alerts":
          matchers:
            - name: alertname
              value: ".+"
              isRegex: true
            - name: syn
              value: ""
              isRegex: false

    rules: {}
    images:
      oc:
        image: quay.io/appuio/oc
        tag: v4.12


    capacityAlerts:
      enabled: true
      groupByNodeLabels: []
      groups:
        PodCapacity:
          rules:
            TooManyPods:
              enabled: true
              annotations:
                message: 'Only {{ $value }} more pods can be started.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/podcapacity.html#SYN_TooManyPods
                description: 'The cluster is close to the limit of running pods. The cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
            ExpectTooManyPods:
              enabled: false
              annotations:
                message: 'Expected to exceed the threshold of running pods in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/podcapacity.html#SYN_ExpectTooManyPods
                description: 'The cluster is getting close to the limit of running pods. Soon the cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'

        ResourceRequests:
          rules:
            TooMuchMemoryRequested:
              enabled: true
              annotations:
                message: 'Only {{ $value }} memory left for new pods.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/resourcerequests.html#SYN_TooMuchMemoryRequested
                description: 'The cluster is close to assigning all memory to running pods. The cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
            ExpectTooMuchMemoryRequested:
              enabled: false
              annotations:
                message: 'Expected to exceed the threshold of requested memory in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/resourcerequests.html#SYN_ExpectTooMuchMemoryRequested
                description: 'The cluster is getting close to assigning all memory to running pods. Soon the cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'
            TooMuchCPURequested:
              enabled: true
              annotations:
                message: 'Only {{ $value }} cpu cores left for new pods.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/resourcerequests.html#SYN_TooMuchCPURequested
                description: 'The cluster is close to assigning all CPU resources to running pods. The cluster might not be able to handle node failures and might soon not be able to start new pods. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
            ExpectTooMuchCPURequested:
              enabled: false
              annotations:
                message: 'Expected to exceed the threshold of requested CPU resources in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/resourcerequests.html#SYN_ExpectTooMuchCPURequested
                description: 'The cluster is getting close to assigning all CPU cores to running pods. Soon the cluster might not be able to handle node failures and might not be able to start new pods. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'

        MemoryCapacity:
          rules:
            ClusterLowOnMemory:
              enabled: true
              annotations:
                message: 'Only {{ $value }} free memory on Worker Nodes.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/memorycapacity.html#SYN_ClusterMemoryUsageHigh
                description: 'The cluster is close to using all of its memory. The cluster might not be able to handle node failures or load spikes. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
            ExpectClusterLowOnMemory:
              enabled: false
              annotations:
                message: 'Cluster expected to run low on memory in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/memorycapacity.html#SYN_ExpectClusterMemoryUsageHigh
                description: 'The cluster is getting close to using all of its memory. Soon the cluster might not be able to handle node failures or load spikes. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'

        CpuCapacity:
          rules:
            ClusterCpuUsageHigh:
              enabled: true
              annotations:
                message: 'Only {{ $value }} idle cpu cores accross cluster.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/cpucapacity.html#SYN_ClusterCpuUsageHigh
                description: 'The cluster is close to using up all CPU resources. The cluster might not be able to handle node failures or load spikes. Consider adding new nodes.'
              for: 30m
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1

            ExpectClusterCpuUsageHigh:
              enabled: false
              annotations:
                message: 'Cluster expected to run low on available CPU resources in 3 days'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/cpucapacity.html#SYN_ExpectClusterCpuUsageHigh
                description: 'The cluster is getting close to using up all CPU resources. The cluster might soon not be able to handle node failures or load spikes. Consider adding new nodes.'
              for: 3h
              labels: {}
              expr:
                # The alert specific threshold is multiplied by this factor. 1 == one node
                factor: 1
                # How much of the past to consider for the prediction
                range: '1d'
                # How far into the future to predict (in seconds)
                predict: '3*24*60*60'

        UnusedCapacity:
          rules:
            ClusterHasUnusedNodes:
              enabled: true
              annotations:
                message: 'Cluster has unused nodes.'
                runbook_url: https://hub.syn.tools/openshift4-monitoring/runbooks/unusedcapacity.html#SYN_ClusterHasUnusedNodes
                description: 'The cluster has {{ $value }} unused nodes. Consider removing unused nodes.'
              for: 8h
              labels: {}
              expr:
                # How many nodes need to be unused.
                # There should be some overcapacity to account for failing nodes and future growth.
                reserved: 4

    secrets: {}
