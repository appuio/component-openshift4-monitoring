= Parameters

The parent key for all of the following parameters is `openshift4_monitoring`.

== `manifests_version`

[horizontal]
type:: string
default:: `release-4.9`

Select which version of the upstream alerting (and recording) rules should be used by the component.
This parameter must be changed to match the cluster's OCP4 minor version.

[TIP]
====
We recommend setting this parameter based on the reported OpenShift version which can be found in the cluster's https://syn.tools/syn/SDDs/0027-dynamic-cluster-facts.html[dynamic facts].

[source,yaml]
----
manifests_version: release-${dynamic_facts:openshiftVersion:Major}.${dynamic_facts:openshiftVersion:Minor}
----
====

== `defaultConfig`

[horizontal]
type:: dictionary
default::
+
[source,yaml]
----
nodeSelector:
  node-role.kubernetes.io/infra: ''
----

A dictionary holding the default configuration which should be applied to all components.


== `upstreamRules.networkPlugin`

[horizontal]
type:: string
default:: `openshift-sdn`

Choose either `openshift-sdn` or `ovn-kubernetes` depending on the installed network plugin.
If a custom network plugin is used, set any other string as the value for this parameter.
This ensures neither openshift-sdn nor OVN-Kubernetes monitoring rules are deployed.


== `upstreamRules.elasticsearchOperator`

[horizontal]
type:: boolean
default:: `true`

Whether the Elasticsearch Operator prometheus rules should be included or not.


== `upstreamRules.clusterSamplesOperator`

[horizontal]
type:: boolean
default:: `true`

Whether the Cluster Samples Operator prometheus rules should be included or not.


== `enableUserWorkload`

[horizontal]
type:: boolean
default:: false

A parameter to enable https://docs.openshift.com/container-platform/4.9/monitoring/enabling-monitoring-for-user-defined-projects.html[monitoring for user-defined projects].

== `configs`

[horizontal]
type:: dictionary
default::
+
[source,yaml]
----
prometheusK8s:
  externalLabels:
    cluster_id: ${cluster:name}
    tenant_id: ${cluster:tenant}
  retention: 8d
  volumeClaimTemplate:
    spec:
      resources:
        requests:
          storage: 50Gi
alertmanagerMain:
  volumeClaimTemplate:
    spec:
      resources:
        requests:
          storage: 2Gi
----

A dictionary holding the configurations for the https://docs.openshift.com/container-platform/latest/monitoring/configuring-the-monitoring-stack.html#configuring-the-monitoring-stack_configuring-the-monitoring-stack[monitoring components].

See the https://docs.openshift.com/container-platform/latest/monitoring/cluster_monitoring/configuring-the-monitoring-stack.html[OpenShift docs] for available parameters.

This table shows the monitoring components you can configure and the keys used to specify the components:

[options="header"]
|====
|Component|Key
|Prometheus Operator|`prometheusOperator`
|Prometheus|`prometheusK8s`
|Alertmanager|`alertmanagerMain`
|kube-state-metrics|`kubeStateMetrics`
|openshift-state-metrics|`openshiftStateMetrics`
|Grafana|`grafana`
|Telemeter Client|`telemeterClient`
|Prometheus Adapter|`k8sPrometheusAdapter`
|Thanos Querier|`thanosQuerier`
|====

== `configsUserWorkload`

[horizontal]
type:: dictionary
default::
+
[source,yaml]
----
prometheusOperator: {}
prometheus: ${openshift4_monitoring:configs:prometheusK8s}
thanosRuler: {}
----

A dictionary holding the configurations for the https://docs.openshift.com/container-platform/latest/monitoring/configuring-the-monitoring-stack.html#configuring-the-monitoring-stack_configuring-the-monitoring-stack[user workload monitoring components].

This table shows the monitoring components you can configure and the keys used to specify the components:

[options="header"]
|====
|Component|Key
|Prometheus Operator|`prometheusOperator`
|Prometheus|`prometheus`
|Thanos Ruler|`thanosRuler`
|====

== `alertManagerConfig`

[horizontal]
type:: dictionary
default::
+
[source,yaml]
----
route:
  group_wait: 0s
  group_interval: 5s
  repeat_interval: 10m
inhibit_rules:
  # Don't send warning or info if a critical is already firing
  - target_match_re:
      severity: warning|info
    source_match:
      severity: critical
    equal:
      - namespace
      - alertname
  # Don't send info if a warning is already firing
  - target_match_re:
      severity: info
    source_match:
      severity: warning
    equal:
      - namespace
      - alertname
----

A dictionary holding the configuration for the AlertManager.

See the https://docs.openshift.com/container-platform/latest/monitoring/cluster_monitoring/configuring-the-monitoring-stack.html#configuring-alertmanager[OpenShift docs] for available parameters.

== `alerts`

[horizontal]
type:: dictionary

Configuration parameters related to influence the resulting alert rules.

=== `ignoreNames`

[horizontal]
type:: list
default:: `[]`

List of https://github.com/prometheus-operator/kube-prometheus[kube-prometheus] alert rule names to be dropped.

=== `customAnnotations`

[horizontal]
type:: dict
default:: `{}`

Maps alert names to sets of custom annotations.
Allows configuring custom annotations for individual alerts.

Example:

[source,yaml]
----
customAnnotations:
  Watchdog:
    runbook_url: https://www.google.com/?q=Watchdog
----

=== `patchRules`
type:: dict
keys:: potential values of parameter `manifests_versions`
default:: See https://github.com/appuio/component-openshift4-monitoring/blob/master/class/defaults.yml[`class/defaults.yml` on GitHub]

The parameter `patchRules` allows users to customize upstream alerts.
The component expects that top-level keys in the parameter correspond to values of parameter `manifests_versions`.
This enables users to selectively patch upstream alerts for a particular OpenShift 4 version.

For each version, the component expects alert names as keys and any alert configuration as values.
See the Prometheus https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/[alerting rules documentation] for extended documentation on configuring alerting rules.

Example:

[source,yaml]
----
patchRules:
  release-4.9:
    SystemMemoryExceedsReservation:
      for: 30m
----

== `silence`

[horizontal]
type:: dict

Parameters to configure the silence CronJob.

=== `schedule`

[horizontal]
type:: string
default:: '0 */4 * * *'

Schedule of the CronJob in cron syntax.

=== `serviceAccountName`

[horizontal]
type:: string
default:: prometheus-k8s

Name of the service account used when running the silence job.
The service account must have permission to access the Alertmanager service through its oAuth proxy.

=== `servingCertsCABundleName`

[horizontal]
type:: string
default:: serving-certs-ca-bundle

Name of the config map containing the CA bundle of the Alertmanager service.

=== `jobHistoryLimit`

[horizontal]
type:: dict

Parameters to configure the numbers of silence job objects to keep.

==== `failed`

[horizontal]
type:: number
default:: 3

Number of failed jobs to keep.

==== `successful`

[horizontal]
type:: number
default:: 3

Number of successful jobs to keep.

== `capacityAlerts`

[horizontal]
type:: dict

This parameter allows users to enable and configure alerts for capacity management.
The capacity alerts are disabled by default and can be enabled by setting the key `capacityAlerts.enabled` to `true`.
Predictive alerts are disabled by default and can be enabled, as exampled by `ExpectClusterCpuUsageHigh.enabled` to `true`.

The dictionary will be transformed into a `PrometheusRule` object by the component.

The component provides 10 alerts that are grouped in four groups.
You can disable or modify each of these alert rules individually.
The fields in these rules will be added to the final `PrometheusRule`, with the exception of `expr`.
The `expr` field contains fields which can be used to tune the default alert rule.
Alternatively the default rule can be completely overwritten by setting the `expr.raw` field (see example below).
See xref:explanations/resource_management.adoc[Resource Management] for an explanation for every alert rule.

Example:

[source,yaml]
---
capacityAlerts:
  enabled: true <1>
  groups:
    PodCapacity:
      rules:
        TooManyPods:
          annotations:
            message: 'The number of pods is too damn high' <2>
          for: 3h <3>
        ExpectTooManyPods:
          expr: <4>
            range: '2d'
            predict: '5*24*60*60'

    ResourceRequests:
      rules:
        TooMuchMemoryRequested:
          enabled: true
          expr:
            raw: sum(kube_pod_resource_request{resource="memory"}) > 9000*1024*1024*1024 <5>
    CpuCapacity:
      rules:
        ClusterCpuUsageHigh:
          enabled: false <6>
        ExpectClusterCpuUsageHigh:
          enabled: false <6>
    UnusedCapacity:
      rules:
        ClusterHasUnusedNodes:
          enabled: false <7>
---
<1> Enables capacity alerts
<2> Changes the alert message for the pod capacity alert
<3> Only alerts for pod capacity if it fires for 3 hours
<4> Change the pod count prediction to look at the last two days and predict the value in five days
<5> Completely overrides the default alert rule and alerts if the total memory request is over 9000 GB
<6> Disables both CPU capacity alert rules
<7> Disables alert if the cluster has unused nodes.


== `rules`

[horizontal]
type:: dict
default:: `{}`

This parameter allows users to configure additional Prometheus rules to deploy on the cluster.

Each key-value pair in the dictionary is transformed into a `PrometheusRule` object by the component.

The component expects that values are dicts themselves and expects that keys in those dicts are prefixed with `record:` or `alert:` to indicate whether the rule is a recording or alerting rule.
The component will transform the keys into fields in the resulting rule by taking the prefix as the field name and the rest of the key as the field value.
For example, key `"record:sum:some:metric:5m"` would be transformed into `record: sum:some:metric:5m` which should define a recording rule with name `sum:some:metric:5m`.
This field is then merged into the provided value which should be a valid rule definition.

See the Prometheus docs for supported configurations for https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/[recording] and https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/[alerting] rules.


Example:

[source,yaml]
---
rules:
  generic-rules:
    "alert:ContainerOOMKilled":
      annotations:
        message: A container ({{$labels.container}}) in pod {{ $labels.namespace }}/{{ $labels.pod }} was OOM killed
      expr: |
        kube_pod_container_status_last_terminated_reason{reason="OOMKilled"} == 1
      labels:
        source: https://git.vshn.net/swisscompks/syn-tenant-repo/-/blob/master/common.yml
        severity: devnull
---

== Example

[source,yaml]
----
defaultConfig:
  nodeSelector:
    node-role.kubernetes.io/infra: ''
configs:
  prometheusK8s:
    volumeClaimTemplate:
      spec:
        resources:
          requests:
            storage: 100Gi
alerts:
  ignoreNames:
    - KubeAPIErrorsHigh
    - KubeClientErrors
----

== `syn_monitoring`

This parameter allows users to enable the component's monitoring configuration.
Currently the component has support for deploying custom `ServiceMonitors` on clusters which use component `prometheus` to manage a custom monitoring stack.

=== `enabled`

[horizontal]
type:: boolean
default:: `true`

Whether to deploy monitoring configurations.
If this parameter is set to `true`, the component will check whether component `prometheus` is present on the cluster.
If the component is missing, no configurations will be deployed regardless of the value of this parameter.

=== `instance`

[horizontal]
type:: string
default:: `null`

This parameter can be used to indicate which custom Prometheus instance should pick up the configurations managed by the component.

If the parameter is set to the empty string, the default instance configured for component `prometheus` will be used.


== `secrets`

[horizontal]
type:: dict
default:: `{}`

A dict of secrets to create in the namespace.
The key is the name of the secret, the value is the content of the secret.
The value must be a dict with a key `stringData` which is a dict of key/value pairs to add to the secret.
