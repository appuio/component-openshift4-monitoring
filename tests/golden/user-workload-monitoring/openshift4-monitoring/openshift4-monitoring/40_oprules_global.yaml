apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: openshift4-monitoring-rules
  namespace: syn-espejote
rules:
  - apiGroups:
      - espejote.io
    resourceNames:
      - openshift4-monitoring-rules
    resources:
      - jsonnetlibraries
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: openshift4-monitoring-rules
  namespace: syn-espejote
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: openshift4-monitoring-rules
subjects:
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-cloud-credential-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-cluster-machine-approver
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-cluster-node-tuning-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-cluster-samples-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-cluster-storage-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-cluster-version
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-console-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-dns-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-etcd-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-image-registry
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-ingress-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-insights
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-kube-apiserver
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-kube-apiserver-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-kube-controller-manager-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-kube-scheduler-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-machine-api
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-machine-config-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-monitoring
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-multus
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-network-operator
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-operator-lifecycle-manager
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-operators-redhat
  - kind: ServiceAccount
    name: openshift4-monitoring-rules
    namespace: openshift-user-workload-monitoring
---
apiVersion: espejote.io/v1alpha1
kind: JsonnetLibrary
metadata:
  labels:
    app.kubernetes.io/name: openshift4-monitoring-rules
  name: openshift4-monitoring-rules
  namespace: syn-espejote
spec:
  data:
    config_v1.json: |-
      {
          "customAnnotations": {

          },
          "excludeNamespaces": [

          ],
          "ignoreGroups": [
              "CloudCredentialOperator",
              "SamplesOperator",
              "kube-apiserver-slos-basic"
          ],
          "ignoreNames": [
              "AlertmanagerReceiversNotConfigured",
              "CannotRetrieveUpdates",
              "ClusterProxyApplySlow",
              "ConfigReloaderSidecarErrors",
              "FailingOperator",
              "GarbageCollectorSyncFailed",
              "ImageRegistryStorageReconfigured",
              "IngressWithoutClassName",
              "KubeCPUOvercommit",
              "KubeCPUQuotaOvercommit",
              "KubeHpaMaxedOut",
              "KubeHpaReplicasMismatch",
              "KubeMemoryOvercommit",
              "KubeMemoryQuotaOvercommit",
              "KubeQuotaExceeded",
              "KubeStateMetricsListErrors",
              "NodeRAIDDegraded",
              "NodeRAIDDiskFailure",
              "NodeSystemSaturation",
              "NodeTextFileCollectorScrapeError",
              "PrometheusOperatorListErrors",
              "PrometheusOperatorNodeLookupErrors",
              "SchedulerLegacyPolicySet",
              "TechPreviewNoUpgrade",
              "ThanosQueryGrpcClientErrorRate",
              "ThanosQueryGrpcServerErrorRate",
              "ThanosQueryHighDNSFailures",
              "ThanosRuleAlertmanagerHighDNSFailures",
              "ThanosRuleQueryHighDNSFailures",
              "node_cpu_load5"
          ],
          "ignoreUserWorkload": [
              "AlertmanagerFailedToSendAlerts",
              "AlertmanagerClusterFailedToSendAlerts",
              "PrometheusOperatorRejectedResources",
              "PrometheusBadConfig",
              "PrometheusDuplicateTimestamps",
              "PrometheusOutOfOrderTimestamps",
              "PrometheusRuleFailures",
              "PrometheusMissingRuleEvaluations",
              "PrometheusTargetLimitHit",
              "PrometheusLabelLimitHit",
              "PrometheusScrapeBodySizeLimitHit",
              "PrometheusScrapeSampleLimitHit",
              "PrometheusTargetSyncFailure"
          ],
          "ignoreWarnings": [
              "ExtremelyHighIndividualControlPlaneCPU",
              "MachineConfigControllerPausedPoolKubeletCA",
              "NodeClockNotSynchronising",
              "NodeFileDescriptorLimit",
              "NodeFilesystemAlmostOutOfFiles",
              "NodeFilesystemAlmostOutOfSpace",
              "NodeFilesystemFilesFillingUp",
              "ThanosRuleRuleEvaluationLatencyHigh",
              "etcdDatabaseHighFragmentationRatio",
              "etcdExcessiveDatabaseGrowth",
              "etcdHighCommitDurations",
              "etcdHighFsyncDurations",
              "etcdHighNumberOfFailedGRPCRequests",
              "etcdMemberCommunicationSlow"
          ],
          "includeNamespaces": [
              "appuio.*",
              "cilium",
              "default",
              "kube-.*",
              "openshift-.*",
              "syn.*"
          ],
          "patchRules": {
              "HighOverallControlPlaneMemory": {
                  "annotations": {
                      "description": "The overall memory usage is high.\nkube-apiserver and etcd might be slow to respond.\nTo fix this, increase memory of the control plane nodes.\n\nThis alert was adjusted to be less sensitive in 4.11.\nNewer Go versions use more memory, if available, to reduce GC pauses.\n\nOld memory behavior can be restored by setting `GOGC=63`.\nSee https://bugzilla.redhat.com/show_bug.cgi?id=2074031 for more details.\n"
                  },
                  "expr": "(\n  1\n  -\n  sum (\n    node_memory_MemFree_bytes\n    + node_memory_Buffers_bytes\n    + node_memory_Cached_bytes\n    AND on (instance)\n    label_replace( kube_node_role{role=\"master\"}, \"instance\", \"$1\", \"node\", \"(.+)\" )\n  ) / sum (\n    node_memory_MemTotal_bytes\n    AND on (instance)\n    label_replace( kube_node_role{role=\"master\"}, \"instance\", \"$1\", \"node\", \"(.+)\" )\n  )\n) * 100 > 80\n"
              },
              "NodeMemoryMajorPagesFaults": {
                  "expr": "rate(node_vmstat_pgmajfault{job=\"node-exporter\"}[5m]) > on (instance) (count by (instance) (node_cpu_info{}) * 100)"
              },
              "PrometheusRemoteWriteBehind": {
                  "annotations": {
                      "runbook_url": "https://hub.syn.tools/openshift4-monitoring/runbooks/remotewrite.html"
                  }
              },
              "PrometheusRemoteWriteDesiredShards": {
                  "annotations": {
                      "runbook_url": "https://hub.syn.tools/openshift4-monitoring/runbooks/remotewrite.html"
                  }
              }
          },
          "teamLabel": null
      }
    renderer_v1.libsonnet: |
      // Helpers from commodore.libsonnet

      local makeMergeable(o) = {
        [key]+: makeMergeable(o[key])
        for key in std.objectFields(o)
        if std.isObject(o[key])
      } + {
        [key]+: o[key]
        for key in std.objectFields(o)
        if std.isArray(o[key])
      } + {
        [key]: o[key]
        for key in std.objectFields(o)
        if !std.isObject(o[key]) && !std.isArray(o[key])
      };

      local renderArray(arr) =
        local realval(v) = std.lstripChars(v, '~');
        local val_state = std.foldl(
          function(a, it) a + it,
          [
            assert
              std.isString(v) :
              "renderArray() doesn't support arrays with non-string entries";
            { [realval(v)]: !std.startsWith(v, '~') }
            for v in arr
          ],
          {}
        );
        std.filter(
          function(val) val_state[val],
          std.objectFields(val_state)
        );

      // Actual rendering

      // Apply this last to avoid problems with alert name matching
      local procPatchRules(group, config) =
        group {
          rules: [
            if std.objectHas(rule, 'alert') then
              rule {
                // Change alert names so we don't get multiple alerts with the same name
                // Ensure Watchdog is not renamed
                alert: if super.alert == 'Watchdog' then 'Watchdog' else 'SYN_' + super.alert,
                labels+: {
                  syn: 'true',
                  // mark alert as belonging to component instance in whose context the
                  // function is called.
                  syn_component: config.componentName,
                  // mark alert as belonging to the team in whose context the
                  // function is called.
                  [if config.teamLabel != null then 'syn_team']: config.teamLabel,
                },
              } + makeMergeable(std.get(config.patchRules, rule.alert, {}))
            else
              // If the rule doesn't have an alert field, return it unchanged (eg. recording rules)
              rule
            for rule in super.rules
          ],
        };

      local procPatchExprUserWorkload(group, config) =
        local dropUserWorkload(alert) = std.member(config.ignoreUserWorkload, alert);
        local patchThingy(field) = std.foldl(
          function(a, b) b(a),
          [
            function(e)
              std.strReplace(
                e,
                'namespace=~"openshift-monitoring|openshift-user-workload-monitoring"',
                'namespace="openshift-monitoring"'
              ),
            function(e)
              std.strReplace(
                e,
                'job=~"alertmanager-main|alertmanager-user-workload"',
                'job="alertmanager-main"'
              ),
            function(e)
              std.strReplace(
                e,
                'job=~"prometheus-k8s|prometheus-user-workload"',
                'job="prometheus-k8s"'
              ),
          ],
          field
        );
        group {
          rules: [
            if dropUserWorkload(std.get(rule, 'alert', '')) then
              rule {
                expr: patchThingy(super.expr),
                // I have no clue what this part is originally for.
                // I know what it does, just not why...
                [if std.objectHas(std.get(rule, 'annotations', {}), 'description') then 'annotations']+: {
                  description: patchThingy(super.description),
                },
              }
            else
              rule
            for rule in super.rules
          ],
        };

      local procPatchExprSelector(group, config) =
        local markerOpenshiftNamespace = 'namespace=~"(openshift-.*|kube-.*|default)"';
        // Replace namespace selector in expression
        local hasNamespaceSelector = std.length(config.renderedIncludeSelector) > 0;
        local hasExclusionSelector = std.length(config.renderedExcludeSelector) > 0;
        group {
          rules: [
            rule {
              expr: std.strReplace(
                super.expr,
                markerOpenshiftNamespace,
                (
                  if hasNamespaceSelector then
                    'namespace=~"(%s)"' % config.renderedIncludeSelector
                  else ''

                ) + (
                  if hasNamespaceSelector && hasExclusionSelector then ',' else ''
                ) + (
                  if hasExclusionSelector then
                    'namespace!~"(%s)"' % config.renderedExcludeSelector
                  else ''
                )
              ),
            }
            for rule in super.rules
          ],
        };

      local procFilterRules(group, config) =
        local getSeverity(r) = std.get(std.get(r, 'labels', {}), 'severity', '');
        local drop(r) =
          // drop rules with severity info
          (
            getSeverity(r) == 'info'
          ) ||
          // drop rules with severity warning that are in the ignoreWarnings list
          (
            getSeverity(r) == 'warning' &&
            std.member(
              config.ignoreWarnings,
              std.get(r, 'alert', '')
            )
          ) ||
          // drop rules with alert name in the ignoreNames list
          (
            std.member(
              config.ignoreNames,
              std.get(r, 'alert', '')
            )
          );
        group {
          rules: std.filter(function(rule) !drop(rule), super.rules),
        };

      local processGroup(group, config) = std.foldl(
        function(a, b) b(a, config),
        [
          procFilterRules,
          procPatchExprSelector,
          procPatchExprUserWorkload,
          procPatchRules,
        ],
        group
      );

      local process(rule, configGlobal, configComponent, enableOwnerRefrences=true) =
        local config = {
          ignoreGroups: renderArray(configGlobal.ignoreGroups + std.get(configComponent, 'ignoreGroups', [])),
          ignoreNames: renderArray(configGlobal.ignoreNames + std.get(configComponent, 'ignoreNames', [])),
          ignoreWarnings: renderArray(configGlobal.ignoreWarnings + std.get(configComponent, 'ignoreWarnings', [])),
          // ignoreUserWorkload only available in configGlobal
          ignoreUserWorkload: renderArray(configGlobal.ignoreUserWorkload),
          // teamLabel in configComponent overrides configGlobal
          teamLabel: if std.get(configComponent, 'teamLabel', '') != '' then std.get(configComponent, 'teamLabel', null) else configGlobal.teamLabel,
          // configGlobal overrides configComponent
          patchRules: std.get(configComponent, 'patchRules', {}) + makeMergeable(configGlobal.patchRules),
          // include and exclude namespaces from expressionsv
          renderedIncludeSelector: std.join('|', renderArray(configGlobal.includeNamespaces + std.get(configComponent, 'includeNamespaces', []))),
          renderedExcludeSelector: std.join('|', renderArray(configGlobal.excludeNamespaces + std.get(configComponent, 'excludeNamespaces', []))),
          componentName: std.get(configComponent, 'component', 'openshift4-monitoring'),
        };
        {
          apiVersion: 'monitoring.coreos.com/v1',
          kind: 'PrometheusRule',
          metadata: {
            labels+: {
              'espejote.io/created-by': 'openshift4-monitoring-rules',
            },
            [if enableOwnerRefrences then 'ownerReferences']: [ {
              controller: true,
              apiVersion: 'monitoring.coreos.com/v1',
              kind: 'PrometheusRule',
              name: rule.metadata.name,
              uid: rule.metadata.uid,
            } ],
            name: 'syn-' + rule.metadata.name,
            namespace: rule.metadata.namespace,
          },
          spec: {
            groups: [
              // Process each group and drop groups in `config.ignoreGroups`
              processGroup(group, config)
              for group in rule.spec.groups
              if !std.member(config.ignoreGroups, group.name)
            ],
          },
        };

      {
        process: process,
      }
